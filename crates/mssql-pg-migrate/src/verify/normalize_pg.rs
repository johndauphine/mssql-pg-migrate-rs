//! PostgreSQL-specific column normalization for row hash computation.
//!
//! This module provides functions to generate PostgreSQL SQL expressions that
//! normalize column values for hash computation, matching the format used by
//! MSSQL's HASHBYTES for cross-database verification.

use crate::source::Column;

/// Check if a column is a text type that should be skipped when hash_text_columns is false.
///
/// Returns true for PostgreSQL text types: text, xml
pub fn is_pg_text_type(data_type: &str) -> bool {
    let dt = data_type.to_lowercase();
    matches!(dt.as_str(), "text" | "xml")
}

/// Generate a PostgreSQL expression to normalize a column value for hashing.
///
/// This produces SQL that converts the column to a consistent text format
/// matching MSSQL's normalization for hash comparison.
pub fn pg_normalize_expr(col: &Column) -> String {
    let col_name = format!("\"{}\"", col.name.replace('"', "\"\""));
    let data_type = col.data_type.to_lowercase();

    match data_type.as_str() {
        // Integer types - just cast to text
        "int2" | "smallint" | "int4" | "integer" | "int" | "int8" | "bigint" | "serial"
        | "bigserial" | "smallserial" => {
            format!("COALESCE({}::text, '')", col_name)
        }

        // Boolean - convert to 1/0 to match MSSQL bit
        "bool" | "boolean" => {
            format!("COALESCE(CASE WHEN {} THEN '1' ELSE '0' END, '')", col_name)
        }

        // Numeric/decimal - normalize precision
        "numeric" | "decimal" | "money" => {
            format!("COALESCE({}::text, '')", col_name)
        }

        // Floating point - use consistent precision
        "float4" | "real" => {
            format!("COALESCE({}::real::text, '')", col_name)
        }
        "float8" | "double precision" => {
            format!("COALESCE({}::double precision::text, '')", col_name)
        }

        // UUID - normalize to lowercase without dashes for cross-platform consistency
        "uuid" => {
            format!("COALESCE(LOWER(REPLACE({}::text, '-', '')), '')", col_name)
        }

        // Date/time types - use ISO format
        "date" => {
            format!("COALESCE(TO_CHAR({}, 'YYYY-MM-DD'), '')", col_name)
        }
        "time" | "time without time zone" => {
            format!("COALESCE(TO_CHAR({}, 'HH24:MI:SS.US'), '')", col_name)
        }
        "timetz" | "time with time zone" => {
            // Use 'US' for microseconds and 'OF' for timezone offset with space separator
            format!("COALESCE(TO_CHAR({}, 'HH24:MI:SS.US OF'), '')", col_name)
        }
        "timestamp" | "timestamp without time zone" => {
            format!(
                "COALESCE(TO_CHAR({}, 'YYYY-MM-DD HH24:MI:SS.US'), '')",
                col_name
            )
        }
        "timestamptz" | "timestamp with time zone" => {
            // Convert to UTC first, then format (no timezone offset needed after conversion)
            format!(
                "COALESCE(TO_CHAR({} AT TIME ZONE 'UTC', 'YYYY-MM-DD HH24:MI:SS.US'), '')",
                col_name
            )
        }

        // Binary - encode as hex
        "bytea" => {
            format!("COALESCE(ENCODE({}, 'hex'), '')", col_name)
        }

        // JSON types - normalize formatting
        "json" => {
            format!("COALESCE({}::text, '')", col_name)
        }
        "jsonb" => {
            // JSONB normalizes key order, so convert to text directly
            format!("COALESCE({}::text, '')", col_name)
        }

        // XML
        "xml" => {
            format!("COALESCE({}::text, '')", col_name)
        }

        // Default: cast to text
        _ => {
            format!("COALESCE({}::text, '')", col_name)
        }
    }
}

/// Generate a PostgreSQL expression to compute row hash for a table.
///
/// This produces an MD5 hash of concatenated normalized column values,
/// matching the format generated by MSSQL's HASHBYTES for verification.
///
/// If `include_text` is false, skips text-type columns (text, xml)
/// for better performance.
pub fn pg_row_hash_expr(columns: &[Column], pk_columns: &[String], include_text: bool) -> String {
    // Get non-PK columns for hashing, optionally excluding text columns
    let hash_columns: Vec<&Column> = columns
        .iter()
        .filter(|c| !pk_columns.contains(&c.name))
        .filter(|c| include_text || !is_pg_text_type(&c.data_type))
        .collect();

    if hash_columns.is_empty() {
        // If no non-PK columns, hash the PK columns
        let pk_exprs: Vec<String> = columns
            .iter()
            .filter(|c| pk_columns.contains(&c.name))
            .map(pg_normalize_expr)
            .collect();

        if pk_exprs.is_empty() {
            return "md5('')".to_string();
        }

        let concat_expr = pk_exprs.join(" || '|' || ");
        return format!("md5({})", concat_expr);
    }

    let col_exprs: Vec<String> = hash_columns.iter().map(|c| pg_normalize_expr(c)).collect();
    let concat_expr = col_exprs.join(" || '|' || ");
    format!("md5({})", concat_expr)
}

#[cfg(test)]
mod tests {
    use super::*;

    fn make_column(name: &str, data_type: &str) -> Column {
        Column {
            name: name.to_string(),
            data_type: data_type.to_string(),
            max_length: 0,
            precision: 0,
            scale: 0,
            is_nullable: true,
            is_identity: false,
            ordinal_pos: 1,
        }
    }

    #[test]
    fn test_pg_normalize_integer() {
        let col = make_column("id", "integer");
        let expr = pg_normalize_expr(&col);
        assert!(expr.contains("::text"));
        assert!(expr.contains("COALESCE"));
    }

    #[test]
    fn test_pg_normalize_boolean() {
        let col = make_column("is_active", "boolean");
        let expr = pg_normalize_expr(&col);
        assert!(expr.contains("CASE WHEN"));
        assert!(expr.contains("'1'"));
        assert!(expr.contains("'0'"));
    }

    #[test]
    fn test_pg_normalize_uuid() {
        let col = make_column("guid", "uuid");
        let expr = pg_normalize_expr(&col);
        assert!(expr.contains("LOWER"));
        assert!(expr.contains("REPLACE"));
    }

    #[test]
    fn test_pg_normalize_timestamp() {
        let col = make_column("created_at", "timestamp");
        let expr = pg_normalize_expr(&col);
        assert!(expr.contains("TO_CHAR"));
        assert!(expr.contains("YYYY-MM-DD"));
    }

    #[test]
    fn test_pg_normalize_bytea() {
        let col = make_column("data", "bytea");
        let expr = pg_normalize_expr(&col);
        assert!(expr.contains("ENCODE"));
        assert!(expr.contains("'hex'"));
    }

    #[test]
    fn test_pg_row_hash_expr() {
        let columns = vec![
            make_column("id", "integer"),
            make_column("name", "text"),
            make_column("created_at", "timestamp"),
        ];
        let pk_columns = vec!["id".to_string()];

        let expr = pg_row_hash_expr(&columns, &pk_columns, true);

        assert!(expr.starts_with("md5("));
        assert!(expr.contains("\"name\""));
        assert!(expr.contains("\"created_at\""));
        // id is a PK so shouldn't be in the hash of non-PK columns
        assert!(!expr.contains("\"id\""));
    }

    #[test]
    fn test_pg_row_hash_expr_only_pk() {
        let columns = vec![make_column("id", "integer")];
        let pk_columns = vec!["id".to_string()];

        let expr = pg_row_hash_expr(&columns, &pk_columns, true);

        // When only PK columns exist, we hash them
        assert!(expr.starts_with("md5("));
        assert!(expr.contains("\"id\""));
    }

    #[test]
    fn test_is_pg_text_type() {
        // Text types that should be skipped
        assert!(is_pg_text_type("text"));
        assert!(is_pg_text_type("TEXT")); // case insensitive
        assert!(is_pg_text_type("xml"));

        // Non-text types that should be included
        assert!(!is_pg_text_type("varchar"));
        assert!(!is_pg_text_type("varchar(100)"));
        assert!(!is_pg_text_type("int"));
        assert!(!is_pg_text_type("timestamp"));
    }

    #[test]
    fn test_pg_row_hash_expr_skip_text() {
        let columns = vec![
            make_column("id", "integer"),
            make_column("name", "varchar"),
            make_column("body", "text"),
            make_column("data", "xml"),
        ];
        let pk_columns = vec!["id".to_string()];

        // With include_text = true, should include all non-PK columns
        let expr_with_text = pg_row_hash_expr(&columns, &pk_columns, true);
        assert!(expr_with_text.contains("\"name\""));
        assert!(expr_with_text.contains("\"body\""));
        assert!(expr_with_text.contains("\"data\""));

        // With include_text = false, should skip text columns
        let expr_without_text = pg_row_hash_expr(&columns, &pk_columns, false);
        assert!(expr_without_text.contains("\"name\""));
        assert!(!expr_without_text.contains("\"body\""));
        assert!(!expr_without_text.contains("\"data\""));
    }
}
